# -*- coding: utf-8 -*-
"""Proyek Sistem Rekomendasi (Tourism).ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1WUAAtaR6QoBCwadButAiCPuTsx7jc2Hj

# Proyek Sistem Rekomendasi
- **Nama:** Putri Mentari
- **Email:** ri.mentaripm@gmail.com
- **ID Dicoding:** pmentari

## Import Semua Packages/Library yang Digunakan
"""

!pip install kaggle

import pandas as pd
import seaborn as sns
import matplotlib.pyplot as plt
import numpy as np

from sklearn.feature_extraction.text import TfidfVectorizer
from sklearn.metrics.pairwise import cosine_similarity
from sklearn.neighbors import NearestNeighbors
from sklearn.model_selection import train_test_split

"""## Data Loading"""

from google.colab import files
files.upload()

!mkdir -p ~/.kaggle
!cp kaggle.json ~/.kaggle/
!chmod 600 /content/kaggle.json
!kaggle datasets download -d aprabowo/indonesia-tourism-destination --force
!unzip indonesia-tourism-destination.zip

"""### Dataset Destinasi Wisata"""

place = pd.read_csv('/content/tourism_with_id.csv')
place

place.info()

"""Dataset ini memiliki menjelaskan informasi tentang tempat wisata. Terdapat 437 baris tempat wisata dan 13 kolom terkait. Dalam dataset ini terdapat 5 kolom bertipe object, 3 kolom bertipe integer, dan 5 kolom bertipe float.

Pengecekan missing values
"""

place.isna().sum()

"""Terdapat 2 kolom yang memiliki missing value, yaitu 232 missing values pada kolom Time_Minutes dan 437 missing values di kolom Unnamed: 11.

Ringkasan statistik dekriptif
"""

place.describe().T

"""Hasil dari statistik deskriptif di atas menunjukkan biaya tiket masuk yang diperlukan berkisar dari Rp0 sampai Rp900.000. Sementara itu, beragam destinasi wisata dapat diakses dari pusat kota dalam 10 menit sampai 6 jam.

Mengecek duplikasi data
"""

print("Jumlah duplikasi: ", place.duplicated().sum())

"""Tidak ada data duplikat dalam dataset ini

Melihat distribusi data
"""

numeric_columns = place.select_dtypes(include='number').columns

plt.figure(figsize=(15, 5))
for i, column in enumerate(numeric_columns, 1):
    plt.subplot(2, 4, i)
    sns.histplot(place[column], kde=True, bins=30)
    plt.title(f'Distribution of {column}')

plt.tight_layout()
plt.show()

"""Terdapat distribusi data yang tidak normal pada kolom numerik dalam dataset ini. Mayoritas destinasi wisata memiliki harga tiket masuk di bawah Rp50.000 dengan rating di antara 4 sampai 5. Selain itu, Mayoritas destinasi wisata dapat ditempuh kurang dari 100 menit dari pusat kota."""

plt.figure(figsize=(12, 6))
ax = sns.barplot(
    x=place['City'].value_counts().index,
    y=place['City'].value_counts().values,
    palette='coolwarm',
    hue=place['City'].value_counts().index,
    legend=False
)

for i, val in enumerate(place['City'].value_counts().values):
    ax.text(i, val + 1, str(val), ha='center', va='bottom', fontsize=9)

plt.title('Jumlah Tempat Wisata di Tiap Kota')
plt.xlabel('Kota')
plt.ylabel('Jumlah Tempat Wisata')
plt.xticks(rotation=45)
plt.tight_layout()
plt.show()

"""Destinasi wisata yang ada dalam dataset ini berada di 5 kota besar di Indonesia, yaitu Yogyakarta, Bandung, Jakarta, Semarang, dan Surabaya. Daerah Yogyakarta dan Bandung memiliki jumlah destinasi wisata paling banyak masing0masing 126 dan 124 destinasi. Surabaya memiliki destinasi wisata paling rendah yaitu 46 destinasi.

### Dataset Rating Destinasi Wisata
"""

rating = pd.read_csv('/content/tourism_rating.csv')
rating

rating.info()

"""Dalam dataset ini menginformasikan rating dari pengunjung yang dinerikan untuk destinasi wisata. Terdapat total 10.000 rating yang diberikan oleh pengunjung.

Pengecekan missing value
"""

rating.isna().sum()

"""Dataset ini tidak memiliki missing values"""

print("Jumlah duplikasi: ", rating.duplicated().sum())

"""Terdapat 79 data duplikat yang terdeteksi.

Ringkasan statistik deskriptif
"""

rating.describe().T

"""Berdasarkan informasi di atas, diketahui terdapat total 10.000 rating yang diberikan oleh 300 pengunjung. Rating yang diberikan oleh pengunjung cukup beragam dari 1 sampai 5 atas pengalamannya saat mengunjungi destinasi wisata.

## Data Preparation

Mengisi missing values pada kolom Time_Minutes dengan median pada dataset destinasi wisata.
"""

place['Time_Minutes'] = place['Time_Minutes'].fillna(place['Time_Minutes'].median())

"""Pengisian dengan median dipilih karena tidak dipengaruhi oleh nilai ekstrim sehingga tahan terhadap outlier. Selain itu, median juga lebih representatif untuk kolom yang memiliki distribusi tidak normal (skewed).

Drop data duplikat pada dataset rating destinasi wisata sehingga hanya tersisa data yang mengandung nilai unik.
"""

rating = rating.drop_duplicates()

rating.shape

"""Sudah tidak ada missing values pada kolom-kolom yang akan digunakan dalma proyek ini.

Merge kedua dataset (destinasi wosata dan rating)
"""

destination = rating.merge(place, on='Place_Id', how='left')

"""Drop kolom tidak relevan dengan proyek atau tidak memiliki informasi sehingga dataset mengandung informasi berkualitas."""

destination = destination.drop(columns=['Description', 'Coordinate', 'Lat', 'Long', 'Unnamed: 11', 'Unnamed: 12'])

destination.info()

"""Berdasarkan hasil merge dataset, terdapat 9921 baris data dan 8 kolom yang dapat digunakan untuk membangun sistem rekomendasi

### Preparation for Content-based FIltering

Menyalin data yang akan digunakan untuk content-based filtering sehingga saat modeling tidak akan menggunakan data utama
"""

datacb = destination[['User_Id', 'Place_Ratings', 'Place_Name', 'Category', 'City', 'Price', 'Time_Minutes']].drop_duplicates().copy()

datacb.info()

datacb['Category'].value_counts()

"""TF-IDF Vectorizer untuk menemukan representasi fitur penting dari setiap kategori destinasi"""

tf = TfidfVectorizer()
tfidf_matrix = tf.fit_transform(datacb['Category'])
tf.get_feature_names_out()

"""Transformasi ke bentuk matriks"""

tfidf_matrix.shape

"""Mengubah vektor tf-idf dalam bentuk matriks"""

tfidf_matrix.todense()

"""Melihat matriks tf-idf beberapa destinasi dan kategorinya"""

pd.DataFrame(
    tfidf_matrix.todense(),
    columns=tf.get_feature_names_out(),
    index=datacb.Place_Name
).sample(10, axis=1).sample(10, axis=0)

"""## Modelling

Cosine Similarity, untuk mengidentifikasi korelasi antara tempat wisata dan kategorinya
"""

cosine_sim = cosine_similarity(tfidf_matrix)
cosine_sim

"""Similarity matrix setiap destinasi"""

cosine_sim_df = pd.DataFrame(cosine_sim, index=datacb['Place_Name'], columns=datacb['Place_Name'])
cosine_sim_df = cosine_sim_df.loc[:, ~cosine_sim_df.columns.duplicated()]

print('Shape:', cosine_sim_df.shape)

cosine_sim_df.sample(10, axis=1).sample(10, axis=0)

"""Rekomendasi Top 20"""

def tourism_recommendations(Place_Name, similarity_data=cosine_sim_df, items=datacb[['Place_Name', 'Category']], k=20):
    if Place_Name not in similarity_data.columns:
        return f"'{Place_Name}' tidak ditemukan di similarity matrix."

    similarities = similarity_data[Place_Name]
    similarities = similarities.drop(Place_Name, errors='ignore')
    top_k = similarities.sort_values(ascending=False).head(k)

    top_k_df = top_k.reset_index()
    top_k_df.columns = ['Place_Name', 'Similarity']

    unique_items = items.drop_duplicates(subset='Place_Name')

    result = top_k_df.merge(unique_items, on='Place_Name')
    return result.drop_duplicates(subset='Place_Name').head(k)

datacb[datacb.Place_Name.eq('Taman Menteng')]

tourism_recommendations('Taman Menteng')

"""Rekomendasi destinasi setiap pengunjung"""

ground_truth = datacb[datacb['Place_Ratings'] >= 3] \
                   .groupby('User_Id')['Place_Name'].apply(list).to_dict()

train_data = {}
test_data = {}

for User_Id, places in ground_truth.items():
    if len(places) < 3:
        continue
    train, test = train_test_split(places, test_size=3, random_state=42)
    train_data[User_Id] = train
    test_data[User_Id] = test

predicted = {}

for User_Id, liked_places in train_data.items():
    recs = []

    for place in liked_places:
        try:
            result_df = tourism_recommendations(place, k=20)
            recs.extend(result_df['Place_Name'].tolist())
        except:
            continue

    seen = set()
    final_recs = []
    for item in recs:
        if item not in seen:
            final_recs.append(item)
            seen.add(item)

    predicted[User_Id] = final_recs[:20]

User_Id = 120
print(f"Rekomendasi untuk User {User_Id}:")

for i, place in enumerate(predicted[User_Id], 1):
    print(f"{i}. {place}")

"""## Evaluasi

Membuat fungsi untuk metrik evaluasi
"""

def precision_at_k(y_true, y_pred, k):
    if not y_pred: return 0
    return len(set(y_true) & set(y_pred[:k])) / k

def recall_at_k(y_true, y_pred, k):
    if not y_true: return 0
    return len(set(y_true) & set(y_pred[:k])) / len(set(y_true))

def f1_at_k(precision, recall):
    if precision + recall == 0:
        return 0
    return 2 * (precision * recall) / (precision + recall)

def average_precision(y_true, y_pred, k):
    if not y_true: return 0
    score = 0.0
    num_hits = 0.0
    for i, p in enumerate(y_pred[:k]):
        if p in y_true:
            num_hits += 1.0
            score += num_hits / (i + 1.0)
    return score / min(len(y_true), k)

def ndcg_at_k(y_true, y_pred, k):
    def dcg(relevance_scores):
        return sum(rel / np.log2(idx + 2) for idx, rel in enumerate(relevance_scores))

    y_pred_k = y_pred[:k]
    relevance = [1 if item in y_true else 0 for item in y_pred_k]
    ideal_relevance = sorted(relevance, reverse=True)

    dcg_val = dcg(relevance)
    idcg_val = dcg(ideal_relevance)

    return dcg_val / idcg_val if idcg_val > 0 else 0

k = 20
precisions, recalls, f1s, maps, ndcgs = [], [], [], [], []

for User_Id in test_data:
    y_true = test_data.get(User_Id, [])
    y_pred = predicted.get(User_Id, [])

    if not y_pred or not y_true:
        continue

    p = precision_at_k(y_true, y_pred, k)
    r = recall_at_k(y_true, y_pred, k)
    f1 = f1_at_k(p, r)
    ap = average_precision(y_true, y_pred, k)
    ndcg = ndcg_at_k(y_true, y_pred, k)

    precisions.append(p)
    recalls.append(r)
    f1s.append(f1)
    maps.append(ap)
    ndcgs.append(ndcg)

print(f'Precision@{k}: {np.mean(precisions):.4f}')
print(f'Recall@{k}:    {np.mean(recalls):.4f}')
print(f'F1@{k}:         {np.mean(f1s):.4f}')
print(f'MAP@{k}:        {np.mean(maps):.4f}')
print(f'NDCG@{k}:       {np.mean(ndcgs):.4f}')

"""Hasil evaluasi tersebut menunjukkan bahwa model yang dibangun belum optimal dalam memberikan rekomendasi destinasi wisata kepada pengunjung.
- Precision@20: 0.0057, berarti sistem ini dapat memberikan banyak rekomendasi destinasi tetapi hanya 0,57% yang relevan dan disukai oleh user.
- Recall@20: 0.0378, berarti sistem rekomendasi hanya mencakup sebagian sebagian kecil item yang relevan, di mana dari semua tempat yang seharusnya direkomendasikan, hanya 3,78% di antaranya yang berhasil ditemukan.
- F1@20: 0.0099, menunjukkan sistem yang tidak seimbang antara ketepatan dan cakupannya.
- MAP@20: 0.0052, berarti bahwa item yang relevan jarang muncul di urutan awal sehingga tidak terlihat oleh user.
- NDCG@20: 0.0357, menunjukkan urutan rekomendasi yang belum baik karena item relevan banyak muncul di posisi bawah.

Proyek ini sudah bisa memberikan rekomendasi destinasi wisata kepada pengunjung, tetapi dari beragam item yang direkomendasikan, item yang relevan dengan preferensi pengunjung masih jarang diberikan/diterima oleh pengunjung.
"""
